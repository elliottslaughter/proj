from proj.config_file import (
    ProjectConfig,
    gen_ifndef_uid,
)
from proj.format import run_formatter
from typing import (
    TextIO,
    Sequence,
    Iterator,
    Optional,
    Union,
    Tuple,
)
from pathlib import Path
from .struct.render import (
    render_header as render_struct_header,
    render_source as render_struct_source,
)
from .struct.spec import (
    StructSpec,
    load_spec as load_struct_spec,
)
from .enum.render import (
    render_header as render_enum_header,
    render_source as render_enum_source,
)
from .enum.spec import (
    EnumSpec,
    load_spec as load_enum_spec,
)
from .variant.spec import (
    VariantSpec,
    load_spec as load_variant_spec,
)
from .variant.render import (
    render_header as render_variant_header,
    render_source as render_variant_source,
)
from proj.hash import get_file_hash
from .. import json as json
from ..json import (
    Json,
)
import logging
from .find_outdated import find_outdated
from proj.paths import (
    FileGroup,
    get_repo_rel_path_for_file_and_library,
    Library,
    ExtensionConfig,
    AbsolutePath,
    File,
    PathRole,
    Repo,
    RepoRelPath,
    get_absolute_path_for_file,
)
from proj.path_info import (
    get_library_and_file_for_path,
)
from proj.path_tree import (
    RepoPathTree,
)

_l = logging.getLogger(__name__)


def find_files(path_tree: RepoPathTree, extension_config: ExtensionConfig) -> Iterator[Tuple[Library, File]]:
    extensions = [".struct.toml", ".enum.toml", ".variant.toml"]
    blacklist = [
        RepoRelPath("triton"),
        RepoRelPath("deps"),
        RepoRelPath("build"),
    ]

    def is_blacklisted(p: RepoRelPath) -> bool:
        for blacklisted in blacklist:
            if found.is_relative_to(blacklisted):
                return True
        return False

    for extension in extensions:
        for found in path_tree.with_extension(extension):
            if not is_blacklisted(found):
                yield get_library_and_file_for_path(found, extension_config)


def render_disclaimer(spec_path: RepoRelPath, f: TextIO) -> None:
    f.write("// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!\n")
    f.write("// If you would like to modify this datatype, instead modify\n")
    f.write(f"// {spec_path}\n")


def render_proj_metadata(spec_path: AbsolutePath, f: TextIO) -> None:
    _hash = get_file_hash(spec_path)
    assert _hash is not None
    proj_metadata = {"generated_from": _hash.hex()}
    f.write("/* proj-data\n")
    f.write(json.dumps(proj_metadata, sort_keys=True, indent=2))
    f.write("\n*/\n")


def _load_proj_metadata(f: TextIO) -> Optional[Json]:
    found = ""
    has_started = False
    has_finished = False
    while not has_finished:
        line = f.readline()
        if line == "":
            break
        else:
            line = line.rstrip()

        if line == "/* proj-data":
            assert not has_started
            has_started = True
        elif line == "*/" and has_started:
            has_finished = True
        elif has_started:
            found += line
    if has_finished:
        return json.loads(found)
    else:
        return None


def load_proj_metadata(p: Path) -> Optional[Json]:
    with p.open("r") as f:
        found = _load_proj_metadata(f)
    return found


def get_existing_hash(p: Path) -> Optional[bytes]:
    if not p.is_file():
        return None

    _loaded = load_proj_metadata(p)
    if _loaded is None:
        return None

    assert isinstance(_loaded, dict)
    as_hex_str = _loaded.get("generated_from", None)
    if as_hex_str is None:
        return None

    return bytes.fromhex(as_hex_str)


def needs_generate_to_path(spec_path: AbsolutePath, out: AbsolutePath) -> bool:
    if not out.is_file():
        return True

    spec_mtime = spec_path.stat().st_mtime
    out_mtime = out.stat().st_mtime

    _l.debug(f"Spec modified time: {spec_mtime!r} vs Out modified time {out_mtime!r}")
    return spec_mtime > out_mtime

def get_path_role_for_spec(spec: Union[StructSpec, EnumSpec, VariantSpec]) -> PathRole:
    if isinstance(spec, StructSpec):
        return PathRole.STRUCT_TOML
    elif isinstance(spec, EnumSpec):
        return PathRole.ENUM_TOML
    elif isinstance(spec, VariantSpec):
        return PathRole.VARIANT_TOML
    else:
        raise ValueError()

def generate_header(
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    repo: Repo,
    library: Library,
    file_group: FileGroup,
    force: bool,
    extension_config: ExtensionConfig,
    ifndef_base: str,
) -> bool:
    spec_repo_rel = get_repo_rel_path_for_file_and_library(
        library=library,
        file=File(file_group, get_path_role_for_spec(spec)),
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path_for_file_and_library(
        library=library,
        file=File(file_group, PathRole.GENERATED_HEADER),
        extension_config=extension_config,
    )

    out_abs = out_repo_rel.to_absolute(repo)
    spec_abs = spec_repo_rel.to_absolute(repo)

    if not (force or needs_generate_to_path(
            spec_path=spec_abs, 
            out=out_abs)):
        _l.debug(
            f"No generation needed for {spec_repo_rel} -> {out_repo_rel}"
        )
        return False

    _l.info(f"Regenerating {spec_repo_rel} -> {out_repo_rel}")

    out_abs.parent.mkdir(exist_ok=True, parents=True)
    with out_abs.open() as f:
        render_disclaimer(spec_path=spec_repo_rel, f=f)
        render_proj_metadata(spec_path=spec_abs, f=f)
        ifndef = gen_ifndef_uid(ifndef_base, out_repo_rel)
        f.write("\n")
        f.write(f"#ifndef {ifndef}\n")
        f.write(f"#define {ifndef}\n")
        f.write("\n")
        if isinstance(spec, StructSpec):
            render_struct_header(spec, f)
        elif isinstance(spec, VariantSpec):
            render_variant_header(spec, f)
        else:
            assert isinstance(spec, EnumSpec)
            render_enum_header(spec, f)
        f.write("\n")
        f.write(f"#endif // {ifndef}\n")

    return True

def get_include_path(library: Library, file_group: FileGroup, header_extension: str) -> str:
    return str(library.name / file_group.group_path.parent / (file_group.group_path.name + header_extension))

def generate_source(
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    repo: Repo,
    library: Library,
    file_group: FileGroup,
    force: bool,
    extension_config: ExtensionConfig,
) -> bool:
    spec_repo_rel = get_repo_rel_path_for_file_and_library(
        library=library,
        file=File(file_group, get_path_role_for_spec(spec)),
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path_for_file_and_library(
        library=library,
        file=File(file_group, PathRole.GENERATED_HEADER),
        extension_config=extension_config,
    )

    out_abs = out_repo_rel.to_absolute(repo)
    spec_abs = spec_repo_rel.to_absolute(repo)

    if not (force or needs_generate_to_path(spec_path=spec_abs, out=out_abs)):
        _l.info(
            f"No generation needed for {spec_repo_rel} -> {out_repo_rel}"
        )
        return False

    _l.info(f"Regenerating {spec_repo_rel} -> {out_repo_rel}")

    include_path = get_include_path(library, file_group, extension_config.header_extension)

    out_abs.parent.mkdir(exist_ok=True, parents=True)
    with out_abs.open() as f:
        render_disclaimer(spec_path=spec_repo_rel, f=f)
        render_proj_metadata(spec_path=spec_abs, f=f)
        f.write("\n")
        f.write(f'#include "{include_path}"\n')
        f.write("\n")
        if isinstance(spec, StructSpec):
            render_struct_source(spec, f)
        elif isinstance(spec, VariantSpec):
            render_variant_source(spec, f)
        else:
            assert isinstance(spec, EnumSpec)
            render_enum_source(spec, f)

    return True


def generate_files(
    repo: Repo, library: Library, spec_file: File, force: bool, extension_config: ExtensionConfig, ifndef_base: str,
) -> Iterator[AbsolutePath]:
    assert spec_file.file_type in [PathRole.STRUCT_TOML, PathRole.ENUM_TOML, PathRole.VARIANT_TOML]

    spec_path = get_absolute_path_for_file(repo, library, spec_file, extension_config)

    spec: Union[StructSpec, EnumSpec, VariantSpec]
    if spec_file.file_type == PathRole.STRUCT_TOML:
        spec = load_struct_spec(spec_path.raw)
    elif spec_file.file_type == PathRole.VARIANT_TOML:
        spec = load_variant_spec(spec_path.raw)
    elif spec_file.file_type == PathRole.ENUM_TOML:
        spec = load_enum_spec(spec_path.raw)
    else:
        raise ValueError()

    header_path = get_absolute_path_for_file(
        repo=repo,
        library=library,
        file=spec_file.group.generated_header,
        extension_config=extension_config,
    )

    source_path = get_absolute_path_for_file(
        repo=repo,
        library=library,
        file=spec_file.group.generated_source,
        extension_config=extension_config,
    )

    if generate_header(
        spec=spec, repo=repo, library=library, file_group=spec_file.group, force=force, extension_config=extension_config, ifndef_base=ifndef_base,
    ):
        yield header_path

    if generate_source(
        spec=spec,
        repo=repo,
        library=library,
        file_group=spec_file.group,
        force=force,
        extension_config=extension_config,
    ):
        yield source_path


def run_dtgen(
    repo: Repo,
    repo_path_tree: RepoPathTree,
    config: ProjectConfig,
    force: bool,
    extension_config: ExtensionConfig,
    ifndef_base: str,
    files: Optional[Sequence[Tuple[Library, File]]] = None,
    delete_outdated: bool = True,
) -> None:
    if files is None:
        files = list(find_files(repo_path_tree, extension_config))

    _l.info("Running dtgen on following files:")
    for f in files:
        _l.info(f"- {f}")
    for (library, spec_file) in files:
        generated = list(
            generate_files(
                repo=repo,
                library=library,
                spec_file=spec_file,
                force=force,
                extension_config=extension_config,
                ifndef_base=ifndef_base,
            )
        )
        if len(generated) > 0:
            run_formatter(config, generated)

    for outdated in find_outdated(repo_path_tree, extension_config):
        if delete_outdated:
            _l.info(f"Removing out-of-date file at {outdated}")
            outdated.unlink()
        else:
            _l.warning(f"Possible out-of-date file at {outdated}")
