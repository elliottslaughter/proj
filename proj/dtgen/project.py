from proj.config_file import (
    get_ifndef_for_path,
    ExtensionConfig,
)
from typing import (
    TextIO,
    Sequence,
    Iterator,
    Optional,
    Union,
    List,
)
from pathlib import (
    Path,
    PurePath,
)
from .struct.render import (
    render_header as render_struct_header,
    render_source as render_struct_source,
)
from .struct.spec import (
    StructSpec,
    parse_struct_spec,
)
from .enum.render import (
    render_header as render_enum_header,
    render_source as render_enum_source,
)
from .enum.spec import (
    EnumSpec,
    parse_enum_spec,
)
from .variant.spec import (
    VariantSpec,
    parse_variant_spec,
)
from .variant.render import (
    render_header as render_variant_header,
    render_source as render_variant_source,
)
from proj.hash import get_file_hash
from .. import json as json
from ..json import (
    Json,
)
import logging
from .find_outdated import find_outdated
from proj.paths import (
    FileGroup,
    File,
    Repo,
    RepoRelPath,
)
from proj.trees import (
    PathTree,
    FileTree,
    FileTreeWithMtime,
    MutableFileTreeWithMtime,
)
import io
import tomllib
from ..unparse_project import (
    get_repo_rel_path,
)
from ..parse_project import (
    parse_file_path,
)
from proj.includes import (
    get_generated_include_path,
)

_l = logging.getLogger(__name__)


def find_dtgen_spec_in_repo(path_tree: PathTree, extension_config: ExtensionConfig) -> List[File]:
    blacklist = [
        PurePath("triton"),
        PurePath("deps"),
        PurePath("build"),
    ]

    def is_blacklisted(p: PurePath) -> bool:
        for blacklisted in blacklist:
            if found.is_relative_to(blacklisted):
                return True
        return False

    result = []
    for found in path_tree.with_extension(".dtg.toml"):
        if not is_blacklisted(found):
            parsed = parse_file_path(RepoRelPath(found), extension_config)
            assert parsed is not None
            result.append(parsed)
    return result


def render_disclaimer(spec_path: RepoRelPath, f: TextIO) -> None:
    f.write("// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!\n")
    f.write("// If you would like to modify this datatype, instead modify\n")
    f.write(f"// {spec_path.path}\n")


def render_proj_metadata(spec_path: PurePath, spec_hash: bytes, f: TextIO) -> None:
    proj_metadata = {"generated_from": spec_hash.hex()}
    f.write("/* proj-data\n")
    f.write(json.dumps(proj_metadata, sort_keys=True, indent=2))
    f.write("\n*/\n")


def _load_proj_metadata(f: TextIO) -> Optional[Json]:
    found = ""
    has_started = False
    has_finished = False
    while not has_finished:
        line = f.readline()
        if line == "":
            break
        else:
            line = line.rstrip()

        if line == "/* proj-data":
            assert not has_started
            has_started = True
        elif line == "*/" and has_started:
            has_finished = True
        elif has_started:
            found += line
    if has_finished:
        return json.loads(found)
    else:
        return None


def load_proj_metadata(p: Path) -> Optional[Json]:
    with p.open("r") as f:
        found = _load_proj_metadata(f)
    return found


def get_existing_hash(p: Path) -> Optional[bytes]:
    if not p.is_file():
        return None

    _loaded = load_proj_metadata(p)
    if _loaded is None:
        return None

    assert isinstance(_loaded, dict)
    as_hex_str = _loaded.get("generated_from", None)
    if as_hex_str is None:
        return None

    return bytes.fromhex(as_hex_str)


def needs_generate_to_path(file_tree: FileTreeWithMtime, spec_path: PurePath, out: PurePath) -> bool:
    if not file_tree.has_file(out):
        _l.debug('File %s does not exist, so generation is needed', out)
        return True

    spec_mtime = file_tree.get_mtime(spec_path)
    out_mtime = file_tree.get_mtime(out)

    _l.debug(f"Spec modified time: {spec_mtime!r} vs Out modified time {out_mtime!r}")
    return spec_mtime > out_mtime

def generate_header_contents(
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    file_group: FileGroup,
    spec_hash: bytes,
    extension_config: ExtensionConfig,
    ifndef_base: str
) -> str:
    spec_repo_rel = get_repo_rel_path(
        file_group.dtgen_toml,
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path(
        file_group.generated_header,
        extension_config=extension_config,
    )

    with io.StringIO() as f:
        render_disclaimer(spec_path=spec_repo_rel, f=f)
        render_proj_metadata(spec_path=spec_repo_rel.path, spec_hash=spec_hash, f=f)
        ifndef = get_ifndef_for_path(ifndef_base, out_repo_rel)
        f.write("\n")
        f.write(f"#ifndef {ifndef}\n")
        f.write(f"#define {ifndef}\n")
        f.write("\n")
        if isinstance(spec, StructSpec):
            render_struct_header(spec, f)
        elif isinstance(spec, VariantSpec):
            render_variant_header(spec, f)
        else:
            assert isinstance(spec, EnumSpec)
            render_enum_header(spec, f)
        f.write("\n")
        f.write(f"#endif // {ifndef}\n")
        return f.getvalue()
 
def generate_header(
    file_tree: MutableFileTreeWithMtime,
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    file_group: FileGroup,
    force: bool,
    extension_config: ExtensionConfig,
    ifndef_base: str,
) -> Optional[PurePath]:

    spec_repo_rel = get_repo_rel_path(
        file_group.dtgen_toml,
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path(
        file_group.generated_header,
        extension_config=extension_config,
    )

    if not (force or needs_generate_to_path(
            file_tree=file_tree,
            spec_path=spec_repo_rel.path, 
            out=out_repo_rel.path)):
        _l.debug(
            f"No generation needed for {spec_repo_rel.path} -> {out_repo_rel.path}"
        )
        return None

    _l.info(f"Regenerating {spec_repo_rel.path} -> {out_repo_rel.path}")

    spec_hash = get_file_hash(file_tree, spec_repo_rel.path)
    assert spec_hash is not None

    file_tree.mkdir(out_repo_rel.path.parent, exist_ok=True, parents=True)
    contents = generate_header_contents(
        spec=spec,
        file_group=file_group,
        spec_hash=spec_hash,
        extension_config=extension_config,
        ifndef_base=ifndef_base,
    )
    file_tree.set_file_contents(out_repo_rel.path, contents, exist_ok=True)
    return out_repo_rel.path

def generate_source_contents(
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    file_group: FileGroup,
    spec_hash: bytes,
    extension_config: ExtensionConfig,
) -> str:
    include_path = get_generated_include_path(file_group, extension_config.header_extension)

    spec_repo_rel = get_repo_rel_path(
        file_group.dtgen_toml,
        extension_config=extension_config,
    )

    with io.StringIO() as f:
        render_disclaimer(spec_path=spec_repo_rel, f=f)
        render_proj_metadata(spec_path=spec_repo_rel.path, spec_hash=spec_hash, f=f)
        f.write("\n")
        f.write(f'#include "{include_path}"\n')
        f.write("\n")
        if isinstance(spec, StructSpec):
            render_struct_source(spec, f)
        elif isinstance(spec, VariantSpec):
            render_variant_source(spec, f)
        else:
            assert isinstance(spec, EnumSpec)
            render_enum_source(spec, f)
        return f.getvalue()

def generate_source(
    file_tree: MutableFileTreeWithMtime,
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    file_group: FileGroup,
    force: bool,
    extension_config: ExtensionConfig,
) -> Optional[PurePath]:

    spec_repo_rel = get_repo_rel_path(
        file_group.dtgen_toml,
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path(
        file_group.generated_source,
        extension_config=extension_config,
    )

    if not (force or needs_generate_to_path(file_tree, spec_path=spec_repo_rel.path, out=out_repo_rel.path)):
        _l.debug(
            f"No generation needed for {spec_repo_rel.path} -> {out_repo_rel.path}"
        )
        return None

    _l.info(f"Regenerating {spec_repo_rel.path} -> {out_repo_rel.path}")
    
    spec_hash = get_file_hash(file_tree, spec_repo_rel.path)
    assert spec_hash is not None

    file_tree.mkdir(out_repo_rel.path.parent, exist_ok=True, parents=True)
    contents = generate_source_contents(
        spec=spec, 
        file_group=file_group,
        spec_hash=spec_hash,
        extension_config=extension_config,
    )
    file_tree.set_file_contents(out_repo_rel.path, contents, exist_ok=True)
    return out_repo_rel.path

def load_spec_file(p: PurePath, repo_file_tree: FileTree) -> Union[StructSpec, EnumSpec, VariantSpec]:
    try:
        raw = tomllib.loads(repo_file_tree.get_file_contents(p))
    except tomllib.TOMLDecodeError as e:
        raise RuntimeError(f"Failed to load spec {p}") from e

    spec_type = raw['type']
    del raw['type']
    if spec_type == 'struct':
        return parse_struct_spec(raw)
    elif spec_type == 'variant':
        return parse_variant_spec(raw)
    elif spec_type == 'enum':
        return parse_enum_spec(raw)
    else:
        raise RuntimeError()

def generate_files(
    file_group: FileGroup, 
    force: bool, 
    extension_config: ExtensionConfig, 
    ifndef_base: str,
    file_tree: MutableFileTreeWithMtime,
) -> List[PurePath]:
    spec_path = get_repo_rel_path(file_group.dtgen_toml, extension_config)

    spec = load_spec_file(spec_path.path, file_tree)

    generated = []

    _l.debug('Generating header file for %s', file_group)
    header_path = generate_header(
        file_tree, 
        spec=spec, 
        file_group=file_group, 
        force=force, 
        extension_config=extension_config, 
        ifndef_base=ifndef_base,
    )

    if header_path is not None:
        generated.append(header_path)

    _l.debug('Generating source file for %s', file_group)
    source_path = generate_source(
        file_tree,
        spec=spec,
        file_group=file_group,
        force=force,
        extension_config=extension_config,
    )

    if source_path is not None:
        generated.append(source_path)

    return generated


def run_dtgen(
    repo: Repo,
    repo_file_tree: MutableFileTreeWithMtime,
    force: bool,
    extension_config: ExtensionConfig,
    ifndef_base: str,
    files: Optional[Sequence[File]] = None,
    delete_outdated: bool = True,
) -> None:
    if files is None:
        files = list(find_dtgen_spec_in_repo(repo_file_tree, extension_config))

    _l.info("Running dtgen on following files:")
    for f in files:
        _l.info(f"- {f}")
    for spec_file in files:
        for generated in generate_files(
            file_group=spec_file.group,
            force=force,
            extension_config=extension_config,
            ifndef_base=ifndef_base,
            file_tree=repo_file_tree,
        ):
            _l.info("Generated %s", generated)

    for outdated in find_outdated(repo_file_tree, extension_config):
        if delete_outdated:
            _l.info(f"Removing out-of-date file at {outdated}")
            repo_file_tree.rm_file(outdated.path)
        else:
            _l.warning(f"Possible out-of-date file at {outdated}")
