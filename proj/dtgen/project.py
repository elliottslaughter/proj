from ..config_file import get_ifndef_for_path
from typing import (
    TextIO,
    Sequence,
    Iterator,
    Optional,
    Union,
    Tuple,
)
from pathlib import (
    Path,
    PurePath,
)
from .struct.render import (
    render_header as render_struct_header,
    render_source as render_struct_source,
)
from .struct.spec import (
    StructSpec,
    parse_struct_spec,
)
from .enum.render import (
    render_header as render_enum_header,
    render_source as render_enum_source,
)
from .enum.spec import (
    EnumSpec,
    parse_enum_spec,
)
from .variant.spec import (
    VariantSpec,
    parse_variant_spec,
)
from .variant.render import (
    render_header as render_variant_header,
    render_source as render_variant_source,
)
from proj.hash import get_file_hash
from .. import json as json
from ..json import (
    Json,
)
import logging
from .find_outdated import find_outdated
from proj.paths import (
    FileGroup,
    ExtensionConfig,
    AbsolutePath,
    File,
    PathRole,
    Repo,
    RepoRelPath,
)
from proj.path_info import (
    get_library_and_file_for_path,
)
from proj.path_tree import (
    PathTree,
)
import io
from proj.file_tree import (
    FileTree,
)
import toml
from ..unparse_project import (
    get_fullpath,
    get_repo_rel_path,
)

_l = logging.getLogger(__name__)


def find_dtgen_spec_in_repo(path_tree: PathTree, extension_config: ExtensionConfig) -> Iterator[File]:
    extensions = [".struct.toml", ".enum.toml", ".variant.toml"]
    blacklist = [
        PurePath("triton"),
        PurePath("deps"),
        PurePath("build"),
    ]

    def is_blacklisted(p: PurePath) -> bool:
        for blacklisted in blacklist:
            if found.is_relative_to(blacklisted):
                return True
        return False

    for extension in extensions:
        for found in path_tree.with_extension(extension):
            if not is_blacklisted(found):
                yield get_library_and_file_for_path(RepoRelPath(found), extension_config)


def render_disclaimer(spec_path: RepoRelPath, f: TextIO) -> None:
    f.write("// THIS FILE WAS AUTO-GENERATED BY proj. DO NOT MODIFY IT!\n")
    f.write("// If you would like to modify this datatype, instead modify\n")
    f.write(f"// {spec_path}\n")


def render_proj_metadata(spec_path: Path, f: TextIO) -> None:
    _hash = get_file_hash(spec_path)
    assert _hash is not None
    proj_metadata = {"generated_from": _hash.hex()}
    f.write("/* proj-data\n")
    f.write(json.dumps(proj_metadata, sort_keys=True, indent=2))
    f.write("\n*/\n")


def _load_proj_metadata(f: TextIO) -> Optional[Json]:
    found = ""
    has_started = False
    has_finished = False
    while not has_finished:
        line = f.readline()
        if line == "":
            break
        else:
            line = line.rstrip()

        if line == "/* proj-data":
            assert not has_started
            has_started = True
        elif line == "*/" and has_started:
            has_finished = True
        elif has_started:
            found += line
    if has_finished:
        return json.loads(found)
    else:
        return None


def load_proj_metadata(p: Path) -> Optional[Json]:
    with p.open("r") as f:
        found = _load_proj_metadata(f)
    return found


def get_existing_hash(p: Path) -> Optional[bytes]:
    if not p.is_file():
        return None

    _loaded = load_proj_metadata(p)
    if _loaded is None:
        return None

    assert isinstance(_loaded, dict)
    as_hex_str = _loaded.get("generated_from", None)
    if as_hex_str is None:
        return None

    return bytes.fromhex(as_hex_str)


def needs_generate_to_path(spec_path: AbsolutePath, out: AbsolutePath) -> bool:
    if not out.is_file():
        return True

    spec_mtime = spec_path.stat().st_mtime
    out_mtime = out.stat().st_mtime

    _l.debug(f"Spec modified time: {spec_mtime!r} vs Out modified time {out_mtime!r}")
    return spec_mtime > out_mtime

def get_path_role_for_spec(spec: Union[StructSpec, EnumSpec, VariantSpec]) -> PathRole:
    if isinstance(spec, StructSpec):
        return PathRole.STRUCT_TOML
    elif isinstance(spec, EnumSpec):
        return PathRole.ENUM_TOML
    elif isinstance(spec, VariantSpec):
        return PathRole.VARIANT_TOML
    else:
        raise ValueError()

def generate_header(
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    file_group: FileGroup,
    force: bool,
    extension_config: ExtensionConfig,
    ifndef_base: str,
) -> Optional[Tuple[PurePath, str]]:

    spec_repo_rel = get_repo_rel_path(
        file_group.dtgen_toml,
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path(
        file_group.generated_source,
        extension_config=extension_config,
    )

    spec_path = get_fullpath(spec_repo_rel)
    out_path = get_fullpath(out_repo_rel)

    if not (force or needs_generate_to_path(
            spec_path=spec_path, 
            out=out_path)):
        _l.debug(
            f"No generation needed for {spec_repo_rel.path} -> {out_repo_rel.path}"
        )
        return None

    _l.info(f"Regenerating {spec_repo_rel.path} -> {out_repo_rel.path}")

    out_path.parent.mkdir(exist_ok=True, parents=True)
    with io.StringIO() as f:
        render_disclaimer(spec_path=spec_repo_rel, f=f)
        render_proj_metadata(spec_path=spec_path, f=f)
        ifndef = get_ifndef_for_path(ifndef_base, out_repo_rel)
        f.write("\n")
        f.write(f"#ifndef {ifndef}\n")
        f.write(f"#define {ifndef}\n")
        f.write("\n")
        if isinstance(spec, StructSpec):
            render_struct_header(spec, f)
        elif isinstance(spec, VariantSpec):
            render_variant_header(spec, f)
        else:
            assert isinstance(spec, EnumSpec)
            render_enum_header(spec, f)
        f.write("\n")
        f.write(f"#endif // {ifndef}\n")
        return (spec_path, f.getvalue())

def get_include_path(file_group: FileGroup, header_extension: str) -> str:
    assert file_group.library is not None
    return str(file_group.library.name / file_group.group_path.parent / (file_group.group_path.name + header_extension))

def generate_source(
    spec: Union[StructSpec, EnumSpec, VariantSpec],
    file_group: FileGroup,
    force: bool,
    extension_config: ExtensionConfig,
) -> Optional[Tuple[Path, str]]:

    spec_repo_rel = get_repo_rel_path(
        file_group.dtgen_toml,
        extension_config=extension_config,
    )

    out_repo_rel = get_repo_rel_path(
        file_group.generated_source,
        extension_config=extension_config,
    )

    spec_path = get_fullpath(spec_repo_rel)
    out_path = get_fullpath(out_repo_rel)

    if not (force or needs_generate_to_path(spec_path=spec_path, out=out_path)):
        _l.info(
            f"No generation needed for {spec_repo_rel} -> {out_repo_rel}"
        )
        return None

    _l.info(f"Regenerating {spec_repo_rel} -> {out_repo_rel}")

    include_path = get_include_path(file_group, extension_config.header_extension)

    out_path.parent.mkdir(exist_ok=True, parents=True)
    with io.StringIO() as f:
        render_disclaimer(spec_path=spec_repo_rel, f=f)
        render_proj_metadata(spec_path=spec_path, f=f)
        f.write("\n")
        f.write(f'#include "{include_path}"\n')
        f.write("\n")
        if isinstance(spec, StructSpec):
            render_struct_source(spec, f)
        elif isinstance(spec, VariantSpec):
            render_variant_source(spec, f)
        else:
            assert isinstance(spec, EnumSpec)
            render_enum_source(spec, f)
        return (out_path, f.getvalue())


def load_spec_file(p: PurePath) -> Union[StructSpec, EnumSpec, VariantSpec]:
    assert p.is_absolute() 

    try:
        raw = toml.loads(p.read_text())
    except toml.TOMLDecodeError as e:
        raise RuntimeError(f"Failed to load spec {p}") from e

    spec_type = raw['type']
    del raw['type']
    if spec_type == 'struct':
        return parse_struct_spec(raw)
    elif spec_type == 'variant':
        return parse_variant_spec(raw)
    elif spec_type == 'enum':
        return parse_enum_spec(raw)
    else:
        raise RuntimeError()

def generate_files(
    file_group: FileGroup, 
    force: bool, 
    extension_config: ExtensionConfig, 
    ifndef_base: str,
    file_tree: FileTree,
) -> Iterator[Tuple[AbsolutePath, str]]:
    spec_path = get_fullpath(file_group.dtgen_toml, extension_config)

    spec = load_spec_file(spec_path)

    header_path = get_fullpath(file_group.generated_header)
    source_path = get_fullpath(file_group.generate_source)

    header_contents = generate_header(
        spec=spec, 
        file_group=file_group, 
        force=force, 
        extension_config=extension_config, 
        ifndef_base=ifndef_base,
    )

    if header_contents is not None:
        yield (header_path, header_contents)

    source_contents = generate_source(
        spec=spec,
        file_group=file_group.group,
        force=force,
        extension_config=extension_config,
    )
    if source_contents is not None:
        yield (source_path, source_contents)


def run_dtgen(
    repo: Repo,
    repo_file_tree: FileTree,
    force: bool,
    extension_config: ExtensionConfig,
    ifndef_base: str,
    files: Optional[Sequence[File]] = None,
    delete_outdated: bool = True,
) -> None:
    if files is None:
        files = list(find_dtgen_spec_in_repo(repo_file_tree, extension_config))

    _l.info("Running dtgen on following files:")
    for f in files:
        _l.info(f"- {f}")
    for spec_file in files:
        generate_files(
            repo=repo,
            spec_file=spec_file,
            force=force,
            extension_config=extension_config,
            ifndef_base=ifndef_base,
            file_tree=repo_file_tree,
        )

    for outdated in find_outdated(repo_file_tree, extension_config):
        if delete_outdated:
            _l.info(f"Removing out-of-date file at {outdated}")
            repo_file_tree.rm_file(outdated)
        else:
            _l.warning(f"Possible out-of-date file at {outdated}")
